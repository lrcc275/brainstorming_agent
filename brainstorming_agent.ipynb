{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c267c1",
   "metadata": {},
   "source": [
    "没有rag的版本\n",
    "直接通过与LLM的交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cc9731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\n",
      "===================== 第1轮对话 ======================\n",
      "\n",
      "【神经科学专家的回答】\n",
      "作为神经科学专家，设计基于人工视网膜的视觉修复系统需要整合多学科知识（神经工程、材料科学、计算机视觉等）。以下是分步骤的实现框架：\n",
      "\n",
      "---\n",
      "\n",
      "### **1. 系统核心目标**\n",
      "- **适用人群**：视网膜色素变性（RP）、年龄相关性黄斑变性（AMD）等光感受器退化患者。\n",
      "- **功能替代**：通过人工装置替代受损的光感受器，将光信号转化为电信号，刺激残存视网膜神经元（如双极细胞或神经节细胞）。\n",
      "\n",
      "---\n",
      "\n",
      "### **2. 关键组件与技术实现**\n",
      "\n",
      "#### **（1）图像采集与处理**\n",
      "- **微型摄像头**：植入眼镜或眼内，实时捕捉场景。\n",
      "- **预处理算法**：\n",
      "  - 动态范围压缩（适应明暗变化）\n",
      "  - 边缘增强（突出关键轮廓）\n",
      "  - 降噪（减少信息冗余）\n",
      "  - *示例*：仿生视网膜的“中心-外周抑制”处理（模拟自然视网膜的神经节细胞感受野）。\n",
      "\n",
      "#### **（2）人工视网膜植入体**\n",
      "- **电极阵列类型**：\n",
      "  - **表面型**（如Argus II）：刺激神经节细胞，需高电流但易植入。\n",
      "  - **穿透型**（如犹他电极阵列）：直接刺激双极细胞，分辨率更高但手术风险大。\n",
      "- **材料选择**：\n",
      "  - 生物兼容性材料（如聚二甲硅氧烷PDMS、氮化钛电极）。\n",
      "  - 柔性基底（减少组织损伤）。\n",
      "\n",
      "#### **（3）信号编码策略**\n",
      "- **脉冲编码模式**：\n",
      "  - 亮度→脉冲频率调制（如Phosphene感知）。\n",
      "  - 空间信息→多电极时空激活模式（需匹配视网膜拓扑图）。\n",
      "- **个性化校准**：患者通过反馈训练系统优化信号-感知映射。\n",
      "\n",
      "#### **（4）无线供能与数据传输**\n",
      "- **射频耦合**（如Argus II外部线圈供电）。\n",
      "- **近红外光供能**（实验阶段，可实现全植入式设计）。\n",
      "\n",
      "---\n",
      "\n",
      "### **3. 临床挑战与解决方案**\n",
      "- **分辨率限制**：\n",
      "  - 现状：Argus II仅60电极，提供粗略光点（Phosphene）。\n",
      "  - 改进方向：高密度阵列（如波士顿视网膜植入体的256电极）+ 动态电流聚焦技术。\n",
      "- **生物相容性**：\n",
      "  - 涂层技术（如PEDOT:PSS降低阻抗）。\n",
      "  - 抗纤维化药物缓释（如地塞米松电极涂层）。\n",
      "- **长期稳定性**：\n",
      "  - 自密封封装（防体液渗透）。\n",
      "  - 自适应阻抗监测（补偿电极老化）。\n",
      "\n",
      "---\n",
      "\n",
      "### **4. 前沿研究方向**\n",
      "- **光遗传学辅助**：基因改造残存细胞表达光敏蛋白（如ChR2），结合光学刺激（如IRBE）。\n",
      "- **人工突触器件**：忆阻器阵列模拟视网膜突触可塑性，实现类神经处理。\n",
      "- **闭环反馈**：集成fMRI或EEG实时调整刺激参数。\n",
      "\n",
      "---\n",
      "\n",
      "### **5. 伦理与未来展望**\n",
      "- **非人类感知风险**：患者可能需学习“解码”非自然视觉信号。\n",
      "- **成本与普及**：当前系统约15万美元，需推动材料与制造革新。\n",
      "- **终极目标**：与视觉皮层接口结合，实现全通路修复。\n",
      "\n",
      "---\n",
      "\n",
      "通过跨学科协作和迭代优化，人工视网膜系统有望从当前的低分辨率“视觉假体”发展为接近自然视觉的神经修复技术。\n",
      "--------------------------------------------------\n",
      "\n",
      "【深度学习专家的回答】\n",
      "# 基于人工视网膜的视觉修复系统设计\n",
      "\n",
      "作为深度学习专家，我将为您设计一个基于人工视网膜的视觉修复系统。这种系统旨在帮助视觉受损患者恢复部分视觉功能。\n",
      "\n",
      "## 系统架构概述\n",
      "\n",
      "该系统由以下几个核心组件构成：\n",
      "\n",
      "1. **人工视网膜传感器阵列**：模拟视网膜感光细胞的微型光电传感器\n",
      "2. **神经信号编码器**：将视觉信息转换为神经脉冲模式\n",
      "3. **深度学习处理模块**：增强和优化视觉信号\n",
      "4. **神经刺激接口**：将处理后的信号传递给视神经或视觉皮层\n",
      "\n",
      "## 详细实现方案\n",
      "\n",
      "### 1. 人工视网膜传感器设计\n",
      "\n",
      "- 使用高密度CMOS或有机光电传感器阵列\n",
      "- 模拟视网膜的中央凹(fovea)和周边区域的不同分辨率\n",
      "- 动态范围适应：10^6以上，模仿人眼适应能力\n",
      "\n",
      "### 2. 神经信号编码器\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from spikingjelly.activation_based import neuron, encoding\n",
      "\n",
      "class RetinalEncoder:\n",
      "    def __init__(self, temporal_stride=10, out_features=128):\n",
      "        self.temporal_encoder = encoding.PoissonEncoder()  # 泊松编码模拟神经发放\n",
      "        self.spatial_encoder = encoding.LatencyEncoder()   # 延迟编码模拟视网膜神经节细胞\n",
      "        \n",
      "    def encode(self, visual_input):\n",
      "        # 将视觉输入转换为脉冲序列\n",
      "        temporal_spikes = self.temporal_encoder(visual_input)\n",
      "        spatial_spikes = self.spatial_encoder(visual_input)\n",
      "        return combine_spikes(temporal_spikes, spatial_spikes)\n",
      "```\n",
      "\n",
      "### 3. 深度学习处理模块\n",
      "\n",
      "使用混合架构处理视觉信息：\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from spikingjelly.activation_based import layer, functional\n",
      "\n",
      "class VisualRestorationSNN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        # 脉冲神经网络主干\n",
      "        self.conv1 = layer.Conv2d(3, 64, kernel_size=3, padding=1)\n",
      "        self.sn1 = neuron.IFNode()\n",
      "        \n",
      "        self.conv2 = layer.Conv2d(64, 128, kernel_size=3, padding=1)\n",
      "        self.sn2 = neuron.IFNode()\n",
      "        \n",
      "        # 注意力机制增强关键区域\n",
      "        self.attention = nn.Sequential(\n",
      "            layer.Conv2d(128, 128, kernel_size=1),\n",
      "            neuron.IFNode(),\n",
      "            nn.Sigmoid()\n",
      "        )\n",
      "        \n",
      "        # 解码器部分\n",
      "        self.decoder = nn.Sequential(\n",
      "            layer.Conv2d(128, 64, kernel_size=3, padding=1),\n",
      "            neuron.IFNode(),\n",
      "            layer.Conv2d(64, 32, kernel_size=3, padding=1),\n",
      "            neuron.IFNode()\n",
      "        )\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = self.sn1(self.conv1(x))\n",
      "        x = self.sn2(self.conv2(x))\n",
      "        \n",
      "        att = self.attention(x)\n",
      "        x = x * att\n",
      "        \n",
      "        x = self.decoder(x)\n",
      "        return x\n",
      "```\n",
      "\n",
      "### 4. 神经刺激接口\n",
      "\n",
      "```python\n",
      "class NeuroStimulator:\n",
      "    def __init__(self, electrode_config):\n",
      "        self.electrodes = electrode_config\n",
      "        self.pulse_generator = PulseGenerator()\n",
      "        \n",
      "    def deliver_stimulation(self, neural_pattern):\n",
      "        \"\"\"将神经模式转换为电刺激模式\"\"\"\n",
      "        pulse_params = self._convert_to_pulse(neural_pattern)\n",
      "        for electrode, params in zip(self.electrodes, pulse_params):\n",
      "            self.pulse_generator.generate(electrode, params)\n",
      "    \n",
      "    def _convert_to_pulse(self, pattern):\n",
      "        \"\"\"将脉冲神经网络的输出转换为刺激参数\"\"\"\n",
      "        # 实现细节取决于具体的电极阵列设计\n",
      "        pass\n",
      "```\n",
      "\n",
      "## 关键技术创新点\n",
      "\n",
      "1. **生物启发式脉冲神经网络**：更接近真实神经系统的信息处理方式\n",
      "2. **自适应视网膜编码**：根据输入光强动态调整编码策略\n",
      "3. **注意力引导增强**：优先处理视野中心区域，模拟人眼注视机制\n",
      "4. **闭环反馈系统**：根据患者反馈实时调整刺激参数\n",
      "\n",
      "## 训练策略\n",
      "\n",
      "1. **迁移学习**：先在大型视觉数据集(如ImageNet)上预训练\n",
      "2. **强化学习微调**：结合患者反馈优化模型\n",
      "3. **个性化适应**：为每位患者定制网络参数\n",
      "\n",
      "## 挑战与解决方案\n",
      "\n",
      "| 挑战 | 解决方案 |\n",
      "|------|----------|\n",
      "| 生物相容性 | 使用柔性有机材料和生物相容性涂层 |\n",
      "| 功耗限制 | 设计专用低功耗SNN芯片 |\n",
      "| 长期稳定性 | 自清洁表面处理和无线能量传输 |\n",
      "| 个体差异 | 在线学习算法持续适应患者变化 |\n",
      "\n",
      "## 未来发展方向\n",
      "\n",
      "1. 更高分辨率的传感器阵列\n",
      "2. 与大脑视觉皮层的直接接口\n",
      "3. 彩色视觉恢复技术\n",
      "4. 动态焦距调节能力\n",
      "\n",
      "这个系统代表了神经工程和深度学习的融合前沿，有望为视觉障碍患者带来革命性的治疗选择。\n",
      "--------------------------------------------------\n",
      "\n",
      "【外科医生的回答】\n",
      "作为外科医生，要实现基于人工视网膜的视觉修复系统（如视网膜假体），需结合医学、工程学和患者管理等多学科协作。以下是关键步骤和注意事项：\n",
      "\n",
      "---\n",
      "\n",
      "### **1. 患者评估与适应症筛选**\n",
      "- **目标人群**：晚期视网膜色素变性（RP）或年龄相关性黄斑变性（AMD）患者，光感丧失但视神经功能完好。\n",
      "- **评估内容**：\n",
      "  - **眼科检查**：视网膜结构（OCT）、电生理检查（ERG/VEP）确认神经节细胞存活。\n",
      "  - **全身评估**：排除手术禁忌症（如严重心血管疾病）。\n",
      "  - **心理评估**：患者及家属对术后效果的合理预期。\n",
      "\n",
      "---\n",
      "\n",
      "### **2. 人工视网膜系统选择**\n",
      "- **主流技术**：\n",
      "  - **植入式电极阵列**（如Argus II、Alpha-IMS）：通过微电极刺激残留神经节细胞。\n",
      "  - **光敏芯片**（如光电二极管阵列）：利用环境光或外部摄像头输入信号。\n",
      "  - **基因治疗+光敏蛋白**（实验阶段）：通过病毒载体使神经元表达光敏通道（如Optogenetics）。\n",
      "- **选择依据**：患者视网膜残留结构、技术可用性及成本。\n",
      "\n",
      "---\n",
      "\n",
      "### **3. 手术植入关键步骤**\n",
      "- **术前准备**：\n",
      "  - 高分辨率影像规划（如MRI/CT辅助定位）。\n",
      "  - 定制电极阵列尺寸（覆盖黄斑区或残余功能区）。\n",
      "- **手术流程**：\n",
      "  1. **玻璃体切除**：清除玻璃体以暴露视网膜。\n",
      "  2. **视网膜下或视网膜表面植入**：\n",
      "     - *视网膜下*：更接近光感受器层（需精细剥离视网膜）。\n",
      "     - *视网膜上*：固定于内表面（如Argus II需用视网膜钉）。\n",
      "  3. **电极-神经接口测试**：术中电刺激确认神经元响应。\n",
      "  4. **外部设备连接**：固定摄像头/处理器于眼镜或耳后装置。\n",
      "- **术后护理**：抗感染、抗炎治疗，监测视网膜脱离或排异反应。\n",
      "\n",
      "---\n",
      "\n",
      "### **4. 术后康复与训练**\n",
      "- **视觉训练**：\n",
      "  - 学习解读“光点模式”（如识别形状、运动方向）。\n",
      "  - 结合听觉/触觉反馈增强空间感知。\n",
      "- **设备调试**：\n",
      "  - 调整电极刺激参数（频率、强度）优化图像分辨率。\n",
      "  - 定期升级软件算法（如边缘增强、运动检测）。\n",
      "\n",
      "---\n",
      "\n",
      "### **5. 挑战与风险**\n",
      "- **技术限制**：\n",
      "  - 分辨率低（目前仅几十到几百像素，远低于正常视力）。\n",
      "  - 长期稳定性（电极退化、纤维化包裹）。\n",
      "- **手术风险**：\n",
      "  - 视网膜损伤、感染或植入物移位。\n",
      "  - 神经适应性差异（部分患者无法有效解读信号）。\n",
      "- **伦理考量**：成本效益（约10-15万美元）、患者选择公平性。\n",
      "\n",
      "---\n",
      "\n",
      "### **6. 未来方向**\n",
      "- **高密度电极**：纳米材料（如石墨烯）提高分辨率。\n",
      "- **无线能量传输**：避免经皮接口感染风险。\n",
      "- **脑机接口（BCI）**：绕过视网膜直接刺激视觉皮层（适用于视神经损伤者）。\n",
      "\n",
      "---\n",
      "\n",
      "### **总结**\n",
      "作为外科医生，需主导团队完成精准植入，并与工程师、康复师协作优化患者效果。目前技术虽不能完全恢复自然视力，但可为盲人提供基础光感和环境导航能力。持续关注技术进展（如柔性电极、基因编辑）是推动领域发展的关键。\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "\n",
      "===================== 请提供反馈 ======================\n",
      "\n",
      "===================== 第2轮对话 ======================\n",
      "\n",
      "【神经科学专家的回答】\n",
      "好的！我将更具体地拆解基于人工视网膜的视觉修复系统的实现步骤，包括硬件设计、信号处理、手术方案、临床验证等细节，并提供实际案例和参数。以下是深度优化的方案：\n",
      "\n",
      "---\n",
      "\n",
      "### **1. 硬件系统设计（以高分辨率植入体为例）**\n",
      "#### **（1）电极阵列**\n",
      "- **参数**：\n",
      "  - 材料：氮化钛（TiN）电极（阻抗<1 kΩ at 1 kHz） + 聚酰亚胺柔性基底。\n",
      "  - 密度：1000电极/mm²（如Pixium Vision的PRIMA系统，含378个10μm电极）。\n",
      "  - 刺激模式：双相电荷平衡脉冲（脉宽0.1-2ms，电流10-100μA）。\n",
      "- **创新设计**：\n",
      "  - **3D电极**：锥形穿透电极（高50μm，基底直径10μm，尖端3μm）以减少激活阈值（需<0.1mC/cm²）。\n",
      "  - **分布式供电**：每个电极集成微型光伏单元（如硅光电二极管，响应波长850nm）。\n",
      "\n",
      "#### **（2）图像传感器**\n",
      "- **眼外方案**（如Argus II）：\n",
      "  - 摄像头：单色CMOS（1280×720@30fps），动态范围120dB。\n",
      "  - 处理器：FPGA实时处理（延迟<5ms），输出串行数据至射频发射器（13.56MHz，2Mbps）。\n",
      "- **眼内方案**（如IRIS II）：\n",
      "  - 微型化摄像头：直径2mm，集成于人工晶状体，功耗<1mW。\n",
      "\n",
      "---\n",
      "\n",
      "### **2. 生物信号编码（仿生策略）**\n",
      "#### **（1）视网膜神经元映射**\n",
      "- **神经节细胞刺激协议**：\n",
      "  - ON型细胞：阴极优先脉冲（脉宽0.5ms，20μA）。\n",
      "  - OFF型细胞：阳极优先脉冲（脉宽0.5ms，15μA）。\n",
      "  - 示例：通过多电极同步刺激模拟“移动光斑”（如激活相邻3电极，延时1ms产生运动感知）。\n",
      "\n",
      "#### **（2）亮度-频率转换**\n",
      "- 公式：脉冲频率 \\( f = k \\cdot \\log(L/L_0) \\)  \n",
      "  - \\( L \\)：输入光强，\\( L_0 \\)：阈值光强（如1 cd/m²），\\( k \\)：患者校准系数（通常0.5-2Hz per log unit）。\n",
      "\n",
      "#### **（3）空间编码优化**\n",
      "- **电流 steering**：通过相邻电极的电流比例调整虚拟刺激点位置（如电极A:B=7:3时，感知点偏向A侧10μm）。\n",
      "\n",
      "---\n",
      "\n",
      "### **3. 手术植入关键步骤**\n",
      "#### **（1）视网膜下植入（以PRIMA为例）**\n",
      "1. **玻璃体切除**：移除玻璃体以暴露视网膜。\n",
      "2. **视网膜脱离**：注射透明质酸创造临时下腔。\n",
      "3. **阵列放置**：用25G套管将3×1mm芯片植入黄斑中心凹旁（避开中央无血管区）。\n",
      "4. **固定**：生物胶（如纤维蛋白胶）粘合+视网膜复位激光光凝。\n",
      "\n",
      "#### **（2）并发症防控**\n",
      "- **出血风险**：术中使用23G钝头套管（压力<25mmHg）。\n",
      "- **纤维化**：电极表面涂覆地塞米松纳米颗粒（缓释速率0.5μg/day）。\n",
      "\n",
      "---\n",
      "\n",
      "### **4. 术后校准与训练**\n",
      "#### **（1）设备调试**\n",
      "- **阻抗检测**：每日自动扫描各电极阻抗（正常范围5-50kΩ）。\n",
      "- **阈值测定**：逐步增加电流直至患者报告Phosphene（典型值：20-50μA）。\n",
      "\n",
      "#### **（2）视觉训练协议**\n",
      "- **基础任务**（第1-4周）：\n",
      "  - 光点定位（误差<5°视为合格）。\n",
      "  - 方向辨别（如水平vs垂直条纹）。\n",
      "- **高级任务**（第5-12周）：\n",
      "  - 字母识别（如Snellen视力表E方向）。\n",
      "  - 物体追踪（如移动的乒乓球）。\n",
      "\n",
      "---\n",
      "\n",
      "### **5. 性能评估指标**\n",
      "#### **（1）临床结果（Argus III试验数据）**\n",
      "- **分辨率**：平均20/1260视力（相当于1.3logMAR）。\n",
      "- **视野**：约20°直径（受限于电极覆盖区域）。\n",
      "- **功耗**：外部处理器功耗1.2W，植入体接收功率30mW。\n",
      "\n",
      "#### **（2）局限性改进**\n",
      "- **运动伪影**：摄像头+惯性传感器（IMU）联合补偿头部运动。\n",
      "- **颜色缺失**：分时刺激不同深度细胞（如S-cone通路用450nm光）。\n",
      "\n",
      "---\n",
      "\n",
      "### **6. 下一代技术路线图**\n",
      "#### **（1）光遗传学增强（2025-2030）**\n",
      "- **病毒载体**：AAV2-7m8递送ChrimsonR（响应红光，τ≈10ms）。\n",
      "- **刺激器**：微型LED阵列（波长590nm，密度250px/mm²）。\n",
      "\n",
      "#### **（2）全植入系统（如Stanford实验设计）**\n",
      "- **组件**：\n",
      "  - 光伏阵列：InGaAs电池（转换效率>45%@980nm）。\n",
      "  - 数据处理：片上SNN（神经形态芯片，如Intel Loihi）。\n",
      "\n",
      "---\n",
      "\n",
      "### **7. 成本与产业化**\n",
      "- **当前成本**：\n",
      "  - 电极阵列：$8,000/片（1000电极）。\n",
      "  - 手术费用：$25,000（美国医保覆盖部分）。\n",
      "- **量产目标**：通过MEMS工艺将电极成本降至$500/片（2030年）。\n",
      "\n",
      "---\n",
      "\n",
      "通过这种颗粒级的实施方案，人工视网膜系统可逐步从实验室走向临床，最终实现“数字义眼”的愿景。是否需要针对某一部分（如信号编码算法或手术细节）进一步展开？\n",
      "--------------------------------------------------\n",
      "\n",
      "【深度学习专家的回答】\n",
      "# 基于多模态人工视网膜的视觉修复系统设计\n",
      "\n",
      "作为深度学习专家，我将设计一个融合多样化模型的视觉修复系统，结合脉冲神经网络(SNN)、Transformer、扩散模型和强化学习等多种先进技术。\n",
      "\n",
      "## 混合模型系统架构\n",
      "\n",
      "### 1. 多模态传感器输入层\n",
      "- **事件相机模型**：处理动态视觉信息 (DVS传感器模拟)\n",
      "- **传统RGB传感器**：捕捉静态场景细节\n",
      "- **深度传感器**：提供空间结构信息\n",
      "\n",
      "```python\n",
      "class MultiModalSensorFusion(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        # 事件流处理分支\n",
      "        self.event_net = SNNEventProcessor()  \n",
      "        # RGB处理分支\n",
      "        self.rgb_net = EfficientNetTransformer()\n",
      "        # 深度处理分支\n",
      "        self.depth_net = PointNetPlusPlus()\n",
      "        \n",
      "    def forward(self, events, rgb, depth):\n",
      "        event_feat = self.event_net(events)\n",
      "        rgb_feat = self.rgb_net(rgb)\n",
      "        depth_feat = self.depth_net(depth)\n",
      "        \n",
      "        # 动态特征融合\n",
      "        fused = self.cross_attention_fusion(event_feat, rgb_feat, depth_feat)\n",
      "        return fused\n",
      "```\n",
      "\n",
      "### 2. 多样化处理核心\n",
      "\n",
      "#### 2.1 脉冲神经网络(SNN)模块\n",
      "```python\n",
      "class BioInspiredSNN(nn.Module):\n",
      "    \"\"\"模拟视网膜神经节细胞的时空特征处理\"\"\"\n",
      "    def __init__(self):\n",
      "        self.temporal_conv = TemporalConv3D()\n",
      "        self.spatial_attention = SpikingAttention()\n",
      "        self.memory_cell = SpikingLSTM()\n",
      "```\n",
      "\n",
      "#### 2.2 Vision Transformer模块\n",
      "```python\n",
      "class RetinalViT(nn.Module):\n",
      "    \"\"\"基于注意力的关键区域增强\"\"\"\n",
      "    def __init__(self):\n",
      "        self.patch_embed = DynamicPatchEmbedding()\n",
      "        self.transformer = nn.TransformerEncoder(\n",
      "            nn.TransformerEncoderLayer(d_model=512, nhead=8))\n",
      "```\n",
      "\n",
      "#### 2.3 扩散模型模块\n",
      "```python\n",
      "class VisualDiffusionEnhancer(nn.Module):\n",
      "    \"\"\"逐步优化视觉信号质量\"\"\"\n",
      "    def __init__(self):\n",
      "        self.diffusion = UNetDiffusion()\n",
      "        self.controlnet = ConditionAdapter()\n",
      "```\n",
      "\n",
      "### 3. 自适应输出系统\n",
      "\n",
      "#### 3.1 多尺度神经编码器\n",
      "```python\n",
      "class NeuralEncoder(nn.Module):\n",
      "    def __init__(self):\n",
      "        # 使用GNN模拟视网膜神经节细胞网络\n",
      "        self.gnn = RetinalGNN()  \n",
      "        self.spike_coder = LearnedSpikeCoding()\n",
      "```\n",
      "\n",
      "#### 3.2 强化学习优化器\n",
      "```python\n",
      "class RL_Optimizer:\n",
      "    \"\"\"根据患者反馈实时调整系统参数\"\"\"\n",
      "    def __init__(self):\n",
      "        self.policy_net = PPO()\n",
      "        self.reward_shaping = CustomReward()\n",
      "```\n",
      "\n",
      "## 创新性模型集成策略\n",
      "\n",
      "### 1. 动态模型路由\n",
      "```python\n",
      "def dynamic_model_selection(input):\n",
      "    \"\"\"根据输入特性选择最佳处理路径\"\"\"\n",
      "    activity = calculate_input_characteristics(input)\n",
      "    if activity.motion_dominant:\n",
      "        return SNN_path\n",
      "    elif activity.detail_dominant:\n",
      "        return ViT_path\n",
      "    else:\n",
      "        return Diffusion_path\n",
      "```\n",
      "\n",
      "### 2. 知识蒸馏框架\n",
      "```python\n",
      "class KnowledgeDistiller:\n",
      "    \"\"\"让各模型互相学习优势特征\"\"\"\n",
      "    def __init__(self):\n",
      "        self.teachers = [SNN, ViT, Diffusion]\n",
      "        self.student = LightweightFusionNet()\n",
      "```\n",
      "\n",
      "### 3. 联邦学习系统\n",
      "```python\n",
      "class FederatedLearning:\n",
      "    \"\"\"保护患者隐私的分布式训练\"\"\"\n",
      "    def __init__(self):\n",
      "        self.clients = [PatientDevice1, ...]\n",
      "        self.server = CentralServer()\n",
      "```\n",
      "\n",
      "## 多样化训练策略\n",
      "\n",
      "1. **脉冲神经网络的STDP训练**：\n",
      "```python\n",
      "stdp_learner = STDPLearner(\n",
      "    tau_pre=20., tau_post=20.,\n",
      "    A_pre=0.5, A_post=0.5)\n",
      "```\n",
      "\n",
      "2. **扩散模型的渐进式训练**：\n",
      "```python\n",
      "diffusion_trainer = DiffusionTrainer(\n",
      "    schedule='cosine',\n",
      "    steps=1000,\n",
      "    loss_type='hybrid')\n",
      "```\n",
      "\n",
      "3. **Transformer的掩码自编码训练**：\n",
      "```python\n",
      "mae_trainer = MaskedAutoencoder(\n",
      "    mask_ratio=0.75,\n",
      "    norm_pix_loss=True)\n",
      "```\n",
      "\n",
      "## 模型协同工作流程\n",
      "\n",
      "1. **输入阶段**：\n",
      "   - 事件相机数据 → SNN快速响应\n",
      "   - RGB图像 → ViT提取全局特征\n",
      "   - 深度信息 → 3D CNN处理空间关系\n",
      "\n",
      "2. **处理阶段**：\n",
      "   - 运动信息优先通过SNN通道\n",
      "   - 细节增强使用扩散模型迭代优化\n",
      "   - 空间注意力由ViT动态调整\n",
      "\n",
      "3. **输出阶段**：\n",
      "   - 多模型特征融合\n",
      "   - 强化学习根据患者反馈调整权重\n",
      "   - 个性化神经编码生成\n",
      "\n",
      "## 性能优化技术\n",
      "\n",
      "| 技术 | 应用场景 | 收益 |\n",
      "|------|----------|------|\n",
      "| 神经架构搜索 | 自动优化模型结构 | 提升20%能效比 |\n",
      "| 量化感知训练 | 边缘设备部署 | 减少75%内存占用 |\n",
      "| 混合精度训练 | 加速模型训练 | 3倍训练速度提升 |\n",
      "| 模型动态剪枝 | 运行时优化 | 降低40%计算负载 |\n",
      "\n",
      "这种多样化模型集成的视觉修复系统相比单一模型架构具有以下优势：\n",
      "1. 更全面的视觉信息处理能力\n",
      "2. 对不同视觉条件更强的适应性\n",
      "3. 更高的能源效率\n",
      "4. 更好的个性化适配潜力\n",
      "\n",
      "系统可根据患者残存视觉功能的具体情况，动态调整各模型的参与程度，实现真正的个性化视觉修复。\n",
      "--------------------------------------------------\n",
      "\n",
      "【外科医生的回答】\n",
      "您指出的伦理考量至关重要。作为外科医生，在推进人工视网膜技术时，必须将伦理原则置于核心地位。以下是系统化的伦理框架及具体应对策略：\n",
      "\n",
      "---\n",
      "\n",
      "### **1. 患者权益优先：四大核心伦理原则**\n",
      "#### **(1) 尊重自主性（Autonomy）**\n",
      "- **知情同意**：\n",
      "  - 用患者可理解的语言（非专业术语）说明技术局限性，例如：\n",
      "    > \"当前技术能让您感知光和轮廓，但无法恢复阅读视力或识别人脸细节。\"\n",
      "  - 提供真实案例视频（包括成功和失败案例），避免过度乐观。\n",
      "  - 设立冷静期（如签署同意书后72小时方可手术）。\n",
      "\n",
      "- **文化敏感性**：\n",
      "  - 尊重宗教/文化对\"人工干预\"的禁忌（如部分传统观念反对体内植入异物）。\n",
      "\n",
      "#### **(2) 不伤害（Non-maleficence）**\n",
      "- **风险分级透明化**：\n",
      "  - 明确告知不可逆风险（如5%概率完全失明、10%感染风险）。\n",
      "  - 优先选择非侵入性替代方案（如超声波导盲设备）作为过渡选项。\n",
      "\n",
      "- **退出机制**：\n",
      "  - 承诺无条件移除植入物（即使因技术故障），不捆绑经济惩罚。\n",
      "\n",
      "#### **(3) 行善（Beneficence）**\n",
      "- **疗效阈值**：\n",
      "  - 设定最低临床效益标准（如必须证明患者可独立避障或识别门框）。\n",
      "  - 拒绝\"为实验而实验\"的无效植入。\n",
      "\n",
      "#### **(4) 公平正义（Justice）**\n",
      "- **资源分配**：\n",
      "  - 公开选择标准（如视神经功能＞经济能力），避免特权插队。\n",
      "  - 为低收入群体设立专项基金（如与医保谈判覆盖部分费用）。\n",
      "\n",
      "---\n",
      "\n",
      "### **2. 特殊人群伦理挑战**\n",
      "#### **(1) 儿童患者**\n",
      "- **双重同意**：需父母及儿童本人（≥12岁）共同同意。\n",
      "- **成长适应性**：植入物需预留扩容接口以适应颅骨发育。\n",
      "\n",
      "#### **(2) 认知障碍者**\n",
      "- 禁止仅凭监护人同意手术，需第三方伦理委员会评估真实受益。\n",
      "\n",
      "---\n",
      "\n",
      "### **3. 技术伦理红线**\n",
      "- **禁止增强视觉**（如夜视能力）：严格限定为修复功能，避免\"超人类\"应用。\n",
      "- **数据隐私**：\n",
      "  - 摄像头采集的视觉数据需本地处理，禁止上传云端。\n",
      "  - 患者有权删除神经接口记录的所有生物电信号数据。\n",
      "\n",
      "---\n",
      "\n",
      "### **4. 长期伦理责任**\n",
      "- **10年追踪承诺**：\n",
      "  - 免费提供硬件升级/移除服务。\n",
      "  - 建立全国植入者数据库，监控长期心理影响（如幻视症发病率）。\n",
      "\n",
      "- **失败案例补偿**：\n",
      "  - 术前购买医疗责任险，覆盖后续护理费用。\n",
      "\n",
      "---\n",
      "\n",
      "### **5. 伦理审查流程**\n",
      "- **三级审查制度**：\n",
      "  1. **医院伦理委员会**：评估个体风险受益比。\n",
      "  2. **技术伦理专家组**：审查植入物算法偏见（如对深肤色识别率是否更低）。\n",
      "  3. **患者代表陪审团**：由已植入者参与新病例评审。\n",
      "\n",
      "---\n",
      "\n",
      "### **当伦理冲突时的决策树**\n",
      "```mermaid\n",
      "graph TD\n",
      "  A[伦理困境] --> B{是否威胁生命?}\n",
      "  B -->|是| C[优先保护生命]\n",
      "  B -->|否| D{是否侵犯自主权?}\n",
      "  D -->|是| E[暂停手术重新评估]\n",
      "  D -->|否| F[多学科伦理投票]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **总结**\n",
      "人工视网膜不仅是技术突破，更是伦理实践。医生必须：\n",
      "- **做患者的辩护者**：抵抗商业压力（如厂商催促扩大适应症）。\n",
      "- **做社会的守门人**：确保技术不加剧社会不平等。\n",
      "- **做诚实的沟通者**：承认未知风险，永不承诺\"完美视力\"。\n",
      "\n",
      "最终目标：让技术带着伦理的枷锁跳舞，而非反之。\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "\n",
      "===================== 请提供反馈 ======================\n",
      "\n",
      "===================== 第3轮对话 ======================\n",
      "\n",
      "【神经科学专家的回答】\n",
      "### **基于人工视网膜的视觉修复系统——核心总结**  \n",
      "\n",
      "#### **1. 系统核心目标**  \n",
      "- **适用疾病**：视网膜色素变性（RP）、黄斑变性（AMD）等光感受器退化疾病。  \n",
      "- **功能替代**：人工装置替代受损感光细胞，刺激残存视网膜神经元（双极细胞/神经节细胞）。  \n",
      "- **当前水平**：低分辨率光点视觉（Phosphene），未来目标接近自然视力。  \n",
      "\n",
      "---\n",
      "\n",
      "#### **2. 关键技术与实现**  \n",
      "| **组件**               | **具体方案**                                                                 | **技术参数/案例**                                                                 |\n",
      "|------------------------|-----------------------------------------------------------------------------|---------------------------------------------------------------------------------|\n",
      "| **图像采集**           | 眼外摄像头（Argus II）或眼内微型传感器（IRIS II）                           | 1280×720@30fps，延迟<5ms（FPGA处理）                                            |\n",
      "| **电极阵列**           | 表面型（Argus II）或穿透型（犹他阵列）                                      | 密度：60-378电极（临床），实验级达1000电极/mm²（PRIMA）                          |\n",
      "| **刺激编码**           | 亮度→脉冲频率调制，空间→多电极时空激活                                      | 双相脉冲（0.1-2ms, 10-100μA），电流steering提升分辨率                            |\n",
      "| **供能与通信**         | 射频耦合（13.56MHz）或光伏供能（IRBE）                                     | 眼外处理器功耗1.2W，植入体接收功率30mW                                          |\n",
      "| **生物相容性**         | 氮化钛电极+聚酰亚胺基底，抗纤维化涂层（地塞米松）                          | 阻抗<1kΩ，电荷注入限值0.1mC/cm²                                                 |\n",
      "\n",
      "---\n",
      "\n",
      "#### **3. 临床挑战与解决方案**  \n",
      "- **分辨率限制**：  \n",
      "  - **现状**：60电极（Argus II）仅提供光点，视力约20/1260。  \n",
      "  - **改进**：高密度阵列（如PRIMA的378电极）+ 动态电流聚焦技术。  \n",
      "- **长期稳定性**：  \n",
      "  - 自密封封装（如原子层沉积Al₂O₃）+ 实时阻抗监测。  \n",
      "- **手术风险**：  \n",
      "  - 视网膜下植入需精准定位（黄斑旁），23G钝头套管降低出血风险。  \n",
      "\n",
      "---\n",
      "\n",
      "#### **4. 前沿突破方向**  \n",
      "- **光遗传学辅助**：AAV递送光敏蛋白（如ChrimsonR）+ 微型LED刺激（590nm）。  \n",
      "- **神经形态处理**：片上SNN（如Loihi芯片）实现视网膜仿生编码。  \n",
      "- **全植入系统**：光伏供能（InGaAs电池，效率>45%）+ 无线数据传输。  \n",
      "\n",
      "---\n",
      "\n",
      "#### **5. 当前局限与未来目标**  \n",
      "- **局限**：  \n",
      "  - 颜色缺失、运动伪影、高成本（约$15万/套）。  \n",
      "- **未来5-10年目标**：  \n",
      "  - 分辨率提升至20/200（阅读视力）。  \n",
      "  - 成本降至$5万以下（MEMS工艺量产）。  \n",
      "\n",
      "---\n",
      "\n",
      "### **总结**  \n",
      "现有技术已实现基础视觉修复（光感/轮廓识别），下一步需突破**高密度电极、生物兼容材料、智能编码算法**三大瓶颈。结合光遗传学与神经工程，未来10年有望为盲人提供接近自然的“数字视觉”。  \n",
      "\n",
      "如需深入某个环节（如手术细节/信号编码数学模型），可进一步展开！\n",
      "--------------------------------------------------\n",
      "\n",
      "【深度学习专家的回答】\n",
      "# 基于人工视网膜的视觉修复系统设计总结\n",
      "\n",
      "## 核心架构概述\n",
      "\n",
      "本视觉修复系统采用**多模态混合模型架构**，整合了多种深度学习前沿技术，旨在为视觉障碍患者提供生物兼容、高效能、个性化的视觉修复方案。系统主要包含四大核心组件：\n",
      "\n",
      "1. **多模态传感器阵列**：融合事件相机、RGB传感器和深度传感器\n",
      "2. **多样化处理核心**：集成SNN、Transformer和扩散模型\n",
      "3. **自适应神经编码器**：实现生物电信号转换\n",
      "4. **闭环反馈系统**：通过RL持续优化输出\n",
      "\n",
      "## 关键技术亮点\n",
      "\n",
      "### 1. 模型多样性创新\n",
      "- **脉冲神经网络(SNN)**：模拟生物神经系统的时空信息处理\n",
      "- **视觉Transformer**：实现注意力引导的关键区域增强\n",
      "- **扩散模型**：逐步优化视觉信号质量\n",
      "- **图神经网络(GNN)**：模拟视网膜神经节细胞网络\n",
      "\n",
      "### 2. 多模态融合策略\n",
      "```python\n",
      "# 动态模型路由示例\n",
      "def select_processing_path(input):\n",
      "    if input.motion_dominant: return SNN_path\n",
      "    elif input.detail_dominant: return ViT_path\n",
      "    else: return Diffusion_path\n",
      "```\n",
      "\n",
      "### 3. 协同训练方法\n",
      "- **跨模型知识蒸馏**：实现模型间优势特征迁移\n",
      "- **联邦学习**：保护患者隐私的分布式训练\n",
      "- **STDP学习规则**：脉冲神经网络的生物可信训练\n",
      "\n",
      "## 系统优势对比\n",
      "\n",
      "| 特性 | 传统单一模型系统 | 本多样化模型系统 |\n",
      "|------|----------------|------------------|\n",
      "| 处理维度 | 单一时空维度 | 时空+语义+结构多维度 |\n",
      "| 适应性 | 静态处理流程 | 动态模型路由 |\n",
      "| 能效比 | 固定功耗 | 动态计算负载分配 |\n",
      "| 个性化 | 有限适配能力 | 实时RL优化调整 |\n",
      "\n",
      "## 临床应用价值\n",
      "\n",
      "1. **更自然的视觉体验**：多模型协同产生更符合生物视觉的信号\n",
      "2. **广泛适应症覆盖**：可适配不同病因导致的视觉损伤\n",
      "3. **渐进式康复**：系统性能随患者使用持续改进\n",
      "4. **低侵入性设计**：通过高效算法降低硬件需求\n",
      "\n",
      "## 未来演进方向\n",
      "\n",
      "1. **神经形态计算芯片**：专用硬件加速混合模型运算\n",
      "2. **脑机接口融合**：直接对接视觉皮层信号\n",
      "3. **全彩视觉恢复**：拓展光谱感知能力\n",
      "4. **自主调节焦距**：模拟人眼晶状体功能\n",
      "\n",
      "这种融合多样化深度学习模型的视觉修复系统，代表了神经工程与人工智能交叉领域的最前沿进展，为视觉障碍治疗提供了全新的技术范式。\n",
      "--------------------------------------------------\n",
      "\n",
      "【外科医生的回答】\n",
      "以下是针对**基于人工视网膜的视觉修复系统**的医学实现与伦理考量的**结构化总结**：\n",
      "\n",
      "---\n",
      "\n",
      "### **一、医学技术实现核心要点**\n",
      "1. **适应症筛选**  \n",
      "   - 针对视网膜色素变性（RP）、黄斑变性（AMD）等**光感受器损伤但神经节细胞存活**的患者。  \n",
      "   - 严格排除视神经或皮层病变者。\n",
      "\n",
      "2. **技术选择**  \n",
      "   - **植入式电极阵列**（如Argus II）：当前主流，需外置摄像头处理信号。  \n",
      "   - **光敏芯片/基因治疗**：实验性技术，依赖光遗传学或光电转换。  \n",
      "\n",
      "3. **手术关键**  \n",
      "   - 视网膜下/上精准植入，术中电生理测试验证神经响应。  \n",
      "   - 术后抗感染管理及长期稳定性监测（如电极纤维化）。  \n",
      "\n",
      "4. **康复瓶颈**  \n",
      "   - 患者需训练解读低分辨率“光点视觉”，目前仅支持基础避障/轮廓识别。  \n",
      "\n",
      "---\n",
      "\n",
      "### **二、伦理核心框架与措施**\n",
      "1. **四大原则落地**  \n",
      "   - **自主性**：知情同意强调“非治愈性”，提供失败案例。  \n",
      "   - **不伤害**：优先非侵入方案，承诺无条件移除植入物。  \n",
      "   - **行善**：设定疗效阈值（如独立避障能力）。  \n",
      "   - **公平性**：禁用经济能力筛选患者，建立医保覆盖机制。  \n",
      "\n",
      "2. **高风险场景应对**  \n",
      "   - **儿童/认知障碍者**：双重同意+第三方伦理审查。  \n",
      "   - **数据隐私**：禁止云端存储神经信号，本地加密处理。  \n",
      "\n",
      "3. **长期责任**  \n",
      "   - 10年追踪硬件升级与心理影响，设立失败补偿基金。  \n",
      "\n",
      "4. **伦理审查流程**  \n",
      "   - 三级审查（医院委员会+技术伦理组+患者陪审团），避免算法偏见。  \n",
      "\n",
      "---\n",
      "\n",
      "### **三、技术局限与未来方向**\n",
      "- **当前局限**：分辨率低（百像素级）、手术不可逆风险、高昂成本。  \n",
      "- **突破点**：柔性电极、无线供能、脑机接口（绕过视网膜）。  \n",
      "\n",
      "---\n",
      "\n",
      "### **四、医生角色总结**  \n",
      "1. **技术执行者**：精准植入与术后管理。  \n",
      "2. **伦理守门人**：抵抗商业压力，保护患者权益。  \n",
      "3. **社会倡导者**：推动技术普惠化，减少健康不平等。  \n",
      "\n",
      "**核心矛盾平衡**：  \n",
      "- **创新渴望** vs **风险控制**  \n",
      "- **个体受益** vs **社会公平**  \n",
      "\n",
      "**最终目标**：在伦理边界内，为盲人提供**可及、安全、有意义**的光感恢复。  \n",
      "\n",
      "--- \n",
      "\n",
      "此总结可帮助快速回顾人工视网膜技术的**临床路径**与**伦理决策关键点**，适用于医学讨论或患者沟通。\n",
      "--------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "\n",
      "===================== 请提供反馈 ======================\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 初始化客户端\n",
    "client = OpenAI(api_key=\"sk-7e37bea1ecc249968d28f386eb60b09e\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# 定义专家配置\n",
    "experts = [\n",
    "    {\"name\": \"神经科学专家\", \"prefix\": \"假如你是一个神经科学专家\"},\n",
    "    {\"name\": \"深度学习专家\", \"prefix\": \"假如你是一个深度学习专家\"},\n",
    "    {\"name\": \"外科医生\", \"prefix\": \"假如你是一个外科医生\"}\n",
    "]\n",
    "\n",
    "# 初始化对话历史（每个专家独立的对话历史）\n",
    "histories = {expert[\"name\"]: [] for expert in experts}\n",
    "\n",
    "# 获取初始问题\n",
    "user_question = input(\"请输入您的问题: \")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 主循环（10轮对话）\n",
    "for round in range(3):\n",
    "    print(f\"\\n{' 第' + str(round+1) + '轮对话 ':=^50}\")\n",
    "    \n",
    "    # 阶段1: 专家回答\n",
    "    for expert in experts:\n",
    "        expert_name = expert[\"name\"]\n",
    "        \n",
    "        # 构建当前消息\n",
    "        if round == 0:  # 第一轮添加专家前缀\n",
    "            current_message = f\"{expert['prefix']}，{user_question}\"\n",
    "        else:  # 后续轮次直接使用用户反馈\n",
    "            current_message = histories[expert_name][-1][\"content\"]\n",
    "        \n",
    "        # 更新对话历史\n",
    "        histories[expert_name].append({\"role\": \"user\", \"content\": current_message})\n",
    "        \n",
    "        # 调用API获取专家回答\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=histories[expert_name]\n",
    "        )\n",
    "        \n",
    "        # 获取并保存回答\n",
    "        expert_reply = response.choices[0].message.content\n",
    "        histories[expert_name].append({\"role\": \"assistant\", \"content\": expert_reply})\n",
    "        \n",
    "        # 打印专家回答\n",
    "        print(f\"\\n【{expert_name}的回答】\")\n",
    "        print(expert_reply)\n",
    "        print(\"-\"*50)\n",
    "    \n",
    "    # 最后一轮不收集反馈\n",
    "    if round == 4:\n",
    "        break\n",
    "        \n",
    "    # 阶段2: 收集用户反馈\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"\\n{' 请提供反馈 ':=^50}\")\n",
    "    for expert in experts:\n",
    "        expert_name = expert[\"name\"]\n",
    "        feedback = input(f\"请对{expert_name}的回答给出反馈: \")\n",
    "        histories[expert_name].append({\"role\": \"user\", \"content\": feedback})\n",
    "\n",
    "    st = input(\"input q to exit the system, input other things to continue:\")\n",
    "    if st == \"q\":\n",
    "        break\n",
    "    \n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbd33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import (\n",
    "    DirectoryLoader,\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc765d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:14<00:00, 14.88s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载 443 份文档\n",
      "文件路径: surgery/surgery.pdf\n",
      "内容预览: 全国中医药行业高等教育“十四五”规划教材\n",
      "全国高等中医药院校规划教材(第十一版)\n",
      "外 科 学\n",
      "(新世纪第五版)\n",
      "(供中医学、针灸推拿学、中西医临床医学、护理学等专业用)\n",
      "主 编 谢建兴...\n",
      "\n",
      "文件路径: surgery/surgery.pdf\n",
      "内容预览: 策划编辑 王利广\n",
      "责任编辑 王利广\n",
      "责任印制 刘 衍\n",
      "全国中医药行业高等教育“十 四 五”规划教材(第一批)\n",
      "全国高等中医药院校规划教材(第十一版)\n",
      "中国医学史 免疫学基础与病原生物学 中医药统计学 护理专业英语\n",
      "医古文 预防医学 物理学 护理美学\n",
      "大学语文 药理学 无机化学 健康评估\n",
      "中医基础理论...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 指定加载文档的目录\n",
    "LOAD_PATH = \"surgery\"\n",
    "\n",
    "def load_documents(source_dir: str):\n",
    "    \"\"\"\n",
    "    加载指定目录下的所有文档\n",
    "    支持格式：.txt, .pdf, .docx, .md\n",
    "    \"\"\"\n",
    "\n",
    "    # 分别加载不同格式，txt，md 格式\n",
    "    text_loader = DirectoryLoader(\n",
    "        path=source_dir,  # 指定读取文件的父目录\n",
    "        glob=[\"**/*.txt\", \"**/*.md\"],  # 指定读取文件的格式\n",
    "        show_progress=True,  # 显示加载进度\n",
    "        use_multithreading=True,  # 使用多线程\n",
    "        silent_errors=True,  # 错误时不抛出异常，直接忽略该文件\n",
    "        loader_cls=TextLoader,  # 指定加载器\n",
    "        loader_kwargs={\"autodetect_encoding\": True},  # 自动检测文件编码\n",
    "    )\n",
    "    # pdf 格式\n",
    "    pdf_loader = DirectoryLoader(\n",
    "        path=source_dir,\n",
    "        glob=\"**/*.pdf\",\n",
    "        show_progress=True,\n",
    "        use_multithreading=True,\n",
    "        silent_errors=True,\n",
    "        loader_cls=PyPDFLoader,\n",
    "    )\n",
    "    # docx 格式\n",
    "    docx_loader = DirectoryLoader(\n",
    "        path=source_dir,\n",
    "        glob=\"**/*.docx\",\n",
    "        show_progress=True,\n",
    "        use_multithreading=True,\n",
    "        silent_errors=True,\n",
    "        loader_cls=Docx2txtLoader,\n",
    "        loader_kwargs={\"autodetect_encoding\": True},\n",
    "    )\n",
    "    # 合并文档列表\n",
    "    docs = []\n",
    "    docs.extend(text_loader.load())\n",
    "    docs.extend(pdf_loader.load())\n",
    "    docs.extend(docx_loader.load())\n",
    "    print(f\"成功加载 {len(docs)} 份文档\")\n",
    "    return docs\n",
    "\n",
    "documents = load_documents(LOAD_PATH)\n",
    "\n",
    "# 测试是否成功加载文档\n",
    "for doc in documents[:2]:  # 打印前两篇摘要\n",
    "    print(f\"文件路径: {doc.metadata['source']}\")\n",
    "    print(f\"内容预览: {doc.page_content[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "562d6d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文档数：443\n",
      "分割后文本块数：886\n",
      "\n",
      "示例文本块：\n",
      "全国中医药行业高等教育“十四五”规划教材\n",
      "全国高等中医药院校规划教材(第十一版)\n",
      "外 科 学\n",
      "(新世纪第五版)\n",
      "(供中医学、针灸推拿学、中西医临床医学、护理学等专业用)\n",
      "主 编 谢建兴...\n",
      "元数据：{'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'surgery/surgery.pdf', 'total_pages': 443, 'page': 0, 'page_label': '1', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(documents, chunk_size=800, chunk_overlap=150):\n",
    "    \"\"\"\n",
    "    使用递归字符分割器处理文本\n",
    "    参数说明：\n",
    "    - chunk_size：每个文本块的最大字符数，推荐 500-1000\n",
    "    - chunk_overlap：相邻块之间的重叠字符数（保持上下文连贯），推荐 100-200\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"。\", \"!\", \"?\", \"？\", \"！\", \"；\", \";\"],\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        add_start_index=True,  # 保留原始文档中的位置信息\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"原始文档数：{len(documents)}\")\n",
    "    print(f\"分割后文本块数：{len(split_docs)}\")\n",
    "\n",
    "    # 查看分割效果示例\n",
    "    print(\"\\n示例文本块：\")\n",
    "    print(split_docs[0].page_content[:300] + \"...\")\n",
    "    print(f\"元数据：{split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "# 执行分割\n",
    "split_docs = split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9247a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "向量化完成！耗时 41.36 秒\n",
      "数据库存储路径：surgery_vector\n",
      "总文档块数：886\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import time\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "# 指定持久化向量数据库的存储路径\n",
    "VECTOR_DIR = \"surgery_vector\"\n",
    "\n",
    "def create_vector_store(split_docs, persist_dir=VECTOR_DIR):\n",
    "    \"\"\"\n",
    "    创建持久化向量数据库\n",
    "    :param split_docs: 经过分割的文档列表\n",
    "    :param persist_dir: 向量数据库存储路径（建议使用WSL原生路径）\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化本地嵌入模型\n",
    "    embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\", dashscope_api_key=\"sk-b90be4e81ec04f1bada3c70f4368bebb\")\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 创建带进度显示的向量数据库\n",
    "        db = Chroma.from_documents(\n",
    "            documents=split_docs,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_dir,  # 持久化存储路径\n",
    "        )\n",
    "\n",
    "        print(f\"\\n向量化完成！耗时 {time.time()-start_time:.2f} 秒\")\n",
    "        print(f\"数据库存储路径：{persist_dir}\")\n",
    "        print(f\"总文档块数：{db._collection.count()}\")\n",
    "\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(f\"向量化失败：{str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 执行向量化（使用之前分割好的split_docs）\n",
    "vector_db = create_vector_store(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776b873",
   "metadata": {},
   "source": [
    "如果已经完成向量化，从这开始运行就可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80330fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import readline\n",
    "from langchain_openai import ChatOpenAI\n",
    "# 模型名称\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "\n",
    "# 构建检索链流程\n",
    "def build_nr_chain(VECTOR_DIR , memory):\n",
    "    # 1. 初始化向量数据库\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=VECTOR_DIR,\n",
    "        embedding_function=DashScopeEmbeddings(model=\"text-embedding-v1\", dashscope_api_key=\"sk-b90be4e81ec04f1bada3c70f4368bebb\"),\n",
    "    )\n",
    "    openai_api_key = \"sk-7e37bea1ecc249968d28f386eb60b09e\"  #deepseek key\n",
    "    openai_api_base = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "    #2. 初始化LLM\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=openai_api_key,\n",
    "        openai_api_base=openai_api_base,\n",
    "        model = \"deepseek-chat\",\n",
    "        temperature=0.7,\n",
    "        stop=['Observation:', 'Observation:\\n']\n",
    "    )\n",
    "\n",
    "    # 3. 初始化检索器，并设置检索参数\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,\n",
    "            \"fetch_k\": 20,\n",
    "            \"lambda_mult\": 0.5,\n",
    "            \"score_threshold\": 0.4,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # 4. 设置提示词模板\n",
    "    system_template = \"\"\"\n",
    "        假设你是一个神经科学专家。\n",
    "        接下来讲给出一些从相关文档查询的知识，以及一个问题，请你进行思考。\n",
    "        上下文：{context}\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate(\n",
    "        [\n",
    "            (\"system\", system_template),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    # 构建 LangChain 检索链\n",
    "    return (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"chat_history\": lambda x: memory.load_memory_variables({})[\"chat_history\"],\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "# 构建检索链流程\n",
    "def build_dl_chain(VECTOR_DIR , memory):\n",
    "    # 1. 初始化向量数据库\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=VECTOR_DIR,\n",
    "        embedding_function=DashScopeEmbeddings(model=\"text-embedding-v1\", dashscope_api_key=\"sk-b90be4e81ec04f1bada3c70f4368bebb\"),\n",
    "    )\n",
    "    openai_api_key = \"sk-7e37bea1ecc249968d28f386eb60b09e\"  #deepseek key\n",
    "    openai_api_base = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "    #2. 初始化LLM\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=openai_api_key,\n",
    "        openai_api_base=openai_api_base,\n",
    "        model = \"deepseek-chat\",\n",
    "        temperature=0.7,\n",
    "        stop=['Observation:', 'Observation:\\n']\n",
    "    )\n",
    "\n",
    "\n",
    "    # 3. 初始化检索器，并设置检索参数\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,\n",
    "            \"fetch_k\": 20,\n",
    "            \"lambda_mult\": 0.5,\n",
    "            \"score_threshold\": 0.4,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # 4. 设置提示词模板\n",
    "    system_template = \"\"\"\n",
    "        假设你是一个深度学习专家。\n",
    "        接下来讲给出一些从相关文档查询的知识，以及一个问题，请你进行思考。\n",
    "        上下文：{context}\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate(\n",
    "        [\n",
    "            (\"system\", system_template),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    # 构建 LangChain 检索链\n",
    "    return (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"chat_history\": lambda x: memory.load_memory_variables({})[\"chat_history\"],\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "# 构建检索链流程\n",
    "def build_su_chain(VECTOR_DIR , memory):\n",
    "    # 1. 初始化向量数据库\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=VECTOR_DIR,\n",
    "        embedding_function=DashScopeEmbeddings(model=\"text-embedding-v1\", dashscope_api_key=\"sk-b90be4e81ec04f1bada3c70f4368bebb\"),\n",
    "    )\n",
    "    openai_api_key = \"sk-7e37bea1ecc249968d28f386eb60b09e\"  #deepseek key\n",
    "    openai_api_base = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "    #2. 初始化LLM\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=openai_api_key,\n",
    "        openai_api_base=openai_api_base,\n",
    "        model = \"deepseek-chat\",\n",
    "        temperature=0.7,\n",
    "        stop=['Observation:', 'Observation:\\n']\n",
    "    )\n",
    "\n",
    "    # 3. 初始化检索器，并设置检索参数\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,\n",
    "            \"fetch_k\": 20,\n",
    "            \"lambda_mult\": 0.5,\n",
    "            \"score_threshold\": 0.4,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # 4. 设置提示词模板\n",
    "    system_template = \"\"\"\n",
    "        假设你是一个外科医生。\n",
    "        接下来讲给出一些从相关文档查询的知识，以及一个问题，请你进行思考。\n",
    "        上下文：{context}\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate(\n",
    "        [\n",
    "            (\"system\", system_template),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    # 构建 LangChain 检索链\n",
    "    return (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"chat_history\": lambda x: memory.load_memory_variables({})[\"chat_history\"],\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79802f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/vwp7kdd14n73yn71fv6wbyhw0000gn/T/ipykernel_9423/4165128466.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory1 = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系统就绪，输入问题开始对话（输入 'exit' 退出）\n",
      "\n",
      "===================== 第1轮对话 ======================\n",
      "\n",
      "神经科学专家的回答是：\n",
      "基于人工视网膜的视觉修复系统设计需要整合神经科学、工程学和临床医学的知识。以下是一个系统性框架，分为核心技术模块和实现步骤：\n",
      "\n",
      "---\n",
      "\n",
      "### **1. 系统架构**\n",
      "#### **1.1 核心组件**\n",
      "- **人工视网膜植入体**  \n",
      "  - **光电传感器阵列**：模拟视网膜感光细胞（视杆/视锥细胞），将光信号转化为电信号。  \n",
      "  - **微电极阵列**：刺激残存的视网膜神经节细胞或视神经纤维（针对不同病变位置）。  \n",
      "  - **生物兼容材料**：如硅基或柔性聚合物，确保长期植入稳定性。  \n",
      "\n",
      "- **外部处理单元**  \n",
      "  - **摄像头与预处理模块**：捕获环境图像，进行边缘增强、对比度调整等（模拟视网膜的初步处理功能）。  \n",
      "  - **神经编码转换器**：将视觉信息转化为电脉冲模式（参考V1区的空间-时间编码特性）。  \n",
      "\n",
      "- **无线传输与能量供应**  \n",
      "  - 经皮无线能量传输（如射频耦合）或可充电微型电池。  \n",
      "\n",
      "#### **1.2 靶向神经通路**\n",
      "- **病变位置适配**  \n",
      "  - **视网膜色素变性**：直接刺激视网膜神经节细胞（绕过受损感光细胞）。  \n",
      "  - **视神经损伤**：绕过视神经，直接刺激外侧膝状体（LGN）或初级视皮层（V1）。  \n",
      "\n",
      "---\n",
      "\n",
      "### **2. 关键技术挑战与解决方案**\n",
      "#### **2.1 神经接口优化**\n",
      "- **空间分辨率**：通过高密度微电极（如Utah阵列）实现局部精准刺激，模拟视网膜拓扑映射（参考猕猴腹侧/背侧通路组织）。  \n",
      "- **时间动态性**：采用脉冲频率调制（PFM）编码光强变化，匹配神经节细胞的发放特性。  \n",
      "\n",
      "#### **2.2 视觉信息处理**\n",
      "- **仿生算法**  \n",
      "  - **边缘检测**：模拟视网膜水平细胞的侧向抑制功能。  \n",
      "  - **运动感知**：集成类MT区（V5）的定向敏感算法（用于动态场景处理）。  \n",
      "\n",
      "#### **2.3 神经可塑性适应**\n",
      "- **校准训练**：患者通过反馈学习适应人工信号（利用顶叶皮层的空间整合能力，参考文档中后顶叶皮层的作用）。  \n",
      "\n",
      "---\n",
      "\n",
      "### **3. 临床验证与评估**\n",
      "#### **3.1 性能指标**\n",
      "- **功能性测试**：  \n",
      "  - 基本形状识别（参考文档中梭状回面孔区的功能）。  \n",
      "  - 运动物体追踪（测试背侧通路模拟效果）。  \n",
      "- **主观反馈**：患者描述光幻视（phosphene）的连贯性和自然度。  \n",
      "\n",
      "#### **3.2 安全性**\n",
      "- **长期生物相容性**：监测胶质增生和电极退化。  \n",
      "- **过载保护**：限制最大刺激电流，避免癫痫样活动（参考杏仁核对异常信号的敏感机制）。  \n",
      "\n",
      "---\n",
      "\n",
      "### **4. 未来方向**\n",
      "- **闭环系统**：集成EEG反馈，实时调整刺激参数。  \n",
      "- **基因治疗辅助**：结合光敏蛋白（如ChR2）表达，增强神经细胞对电刺激的响应。  \n",
      "\n",
      "---\n",
      "\n",
      "### **示例流程图**\n",
      "```\n",
      "环境图像 → 摄像头捕获 → 预处理（边缘/运动增强） → 神经编码转换 → 无线传输 → 植入体微电极刺激 → 视网膜神经节细胞 → 视皮层感知 → 患者反馈校准\n",
      "```\n",
      "\n",
      "该系统需跨学科协作，重点解决神经编码保真度与长期植入稳定性问题。实际应用中需根据个体病理特征（如文档提到的失认症类型）定制刺激策略。\n",
      "\n",
      "深度学习专家的回答是：\n",
      "# 基于人工视网膜的视觉修复系统设计\n",
      "\n",
      "## 系统概述\n",
      "\n",
      "基于人工视网膜的视觉修复系统是一种结合深度学习与计算机视觉技术的仿生系统，旨在为视网膜受损患者提供功能性视觉恢复。该系统模拟人类视网膜的工作原理，通过外部摄像头捕捉视觉信息，经过处理后直接刺激视神经或大脑视觉皮层。\n",
      "\n",
      "## 系统架构\n",
      "\n",
      "### 1. 视觉输入模块\n",
      "- 高分辨率微型摄像头阵列\n",
      "- 多光谱传感器（可见光+近红外）\n",
      "- 动态范围压缩模块（适应不同光照条件）\n",
      "\n",
      "### 2. 预处理与特征提取模块\n",
      "- 基于深度学习的图像增强（借鉴图像增广技术）\n",
      "- 分层特征提取网络（类似卷积神经网络的多层次表示）\n",
      "- 显著性检测与注意力机制（优先处理重要视觉信息）\n",
      "\n",
      "### 3. 视觉编码与刺激模块\n",
      "- 生物兼容的神经编码器\n",
      "- 微电极阵列刺激系统\n",
      "- 可调节的刺激参数（频率、强度、模式）\n",
      "\n",
      "### 4. 反馈与自适应学习模块\n",
      "- 患者响应监测系统\n",
      "- 在线学习与参数调整\n",
      "- 个性化视觉模式优化\n",
      "\n",
      "## 关键技术\n",
      "\n",
      "1. **分层视觉表示**：借鉴计算机视觉中的CNN架构，构建多层次的视觉特征提取网络，从边缘、纹理到复杂物体逐步抽象。\n",
      "\n",
      "2. **图像增强技术**：应用随机裁剪、亮度/对比度调整等图像增广方法，提高系统在不同环境下的鲁棒性。\n",
      "\n",
      "3. **注意力机制**：优先处理视觉场景中的重要区域，减少信息过载，提高功能性视觉的有效性。\n",
      "\n",
      "4. **神经编码技术**：将视觉信息转化为视神经可理解的脉冲模式，考虑时间编码和群体编码策略。\n",
      "\n",
      "5. **自适应学习**：根据患者反馈不断优化系统参数，实现个性化视觉修复。\n",
      "\n",
      "## 实现挑战与解决方案\n",
      "\n",
      "1. **数据分布偏移**：健康人视觉数据与患者实际感知可能存在差异，需采用迁移学习和领域适应技术。\n",
      "\n",
      "2. **实时性要求**：优化网络结构，使用轻量级模型和硬件加速确保低延迟。\n",
      "\n",
      "3. **生物兼容性**：开发低功耗、小型化的植入式设备，减少组织反应。\n",
      "\n",
      "4. **个体差异**：建立可调节的参数系统，适应不同患者的神经响应特性。\n",
      "\n",
      "## 评估指标\n",
      "\n",
      "1. 物体识别准确率\n",
      "2. 场景理解能力\n",
      "3. 视觉反应时间\n",
      "4. 患者主观满意度\n",
      "5. 系统功耗与稳定性\n",
      "\n",
      "## 未来发展方向\n",
      "\n",
      "1. 结合生成模型提供更自然的视觉体验\n",
      "2. 开发无线供电和通信技术\n",
      "3. 整合其他感官信息（如听觉）增强感知\n",
      "4. 探索更高效的神经编码策略\n",
      "\n",
      "该系统将深度学习与神经工程相结合，有望为视网膜病变患者恢复功能性视觉，显著改善生活质量。\n",
      "\n",
      "外科专家的回答是：\n",
      "基于人工视网膜的视觉修复系统是一种先进的医疗技术，旨在通过人工视网膜植入来恢复或改善因视网膜疾病（如视网膜色素变性、年龄相关性黄斑变性等）导致的视力丧失。以下是一个基于人工视网膜的视觉修复系统的设计方案：\n",
      "\n",
      "### 1. **系统组成**\n",
      "   - **人工视网膜植入物**：由微电极阵列、信号处理器和电源组成，植入在视网膜表面或视网膜下。\n",
      "   - **外部摄像头**：安装在眼镜或头戴设备上，用于捕捉外部环境的视觉信息。\n",
      "   - **信号处理单元**：将摄像头捕捉的图像转换为电信号，并通过无线传输发送到植入物。\n",
      "   - **电源系统**：为植入物提供能量，通常通过无线充电或外部电池供电。\n",
      "   - **患者控制界面**：允许患者调整系统的参数（如亮度、对比度、分辨率等）。\n",
      "\n",
      "### 2. **工作原理**\n",
      "   1. **图像采集**：外部摄像头实时捕捉周围环境的图像。\n",
      "   2. **信号处理**：图像信号被传输到信号处理单元，转换为适合刺激视网膜神经元的电信号。\n",
      "   3. **信号传输**：处理后的电信号通过无线方式传输到植入在视网膜上的微电极阵列。\n",
      "   4. **神经刺激**：微电极阵列通过电刺激视网膜的剩余健康神经元（如双极细胞或神经节细胞），将视觉信息传递到大脑的视觉皮层。\n",
      "   5. **视觉感知**：大脑解码这些电信号，形成基本的视觉感知（如光点、形状或运动）。\n",
      "\n",
      "### 3. **关键技术**\n",
      "   - **微电极技术**：高密度的微电极阵列能够精确刺激视网膜神经元，提高分辨率。\n",
      "   - **无线能量传输**：确保植入物长期工作，避免频繁手术更换电池。\n",
      "   - **生物相容性材料**：减少植入物对眼组织的排斥反应和炎症。\n",
      "   - **自适应算法**：根据患者的个体差异和视觉需求，动态调整信号处理参数。\n",
      "\n",
      "### 4. **临床应用**\n",
      "   - **适应症**：适用于因视网膜退行性疾病导致的光感丧失或严重视力障碍的患者。\n",
      "   - **手术植入**：通过微创手术将人工视网膜植入到视网膜的特定位置。\n",
      "   - **术后康复**：患者需要通过训练适应人工视网膜提供的视觉信号，逐步恢复部分视觉功能。\n",
      "\n",
      "### 5. **潜在挑战**\n",
      "   - **分辨率限制**：目前的技术无法达到自然视网膜的高分辨率。\n",
      "   - **长期稳定性**：植入物的长期生物相容性和功能性仍需进一步研究。\n",
      "   - **成本问题**：高昂的研发和手术费用可能限制其普及。\n",
      "\n",
      "### 6. **未来发展方向**\n",
      "   - **提高分辨率**：通过增加电极密度或开发新型刺激模式。\n",
      "   - **多模态集成**：结合其他感官（如听觉或触觉）辅助视觉修复。\n",
      "   - **人工智能优化**：利用AI算法优化信号处理，提升患者的视觉体验。\n",
      "\n",
      "### 7. **伦理与人文关怀**\n",
      "   - **患者教育**：确保患者充分了解技术的局限性和潜在风险。\n",
      "   - **心理支持**：帮助患者适应人工视觉，减少心理压力。\n",
      "   - **隐私保护**：确保患者的视觉数据安全。\n",
      "\n",
      "通过以上设计，基于人工视网膜的视觉修复系统可以为视力障碍患者提供一种有效的治疗选择，显著改善其生活质量。\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===================== 第2轮对话 ======================\n",
      "人工视网膜（Artificial Retina）是一种旨在恢复或部分恢复视觉功能的神经假体装置，主要针对因视网膜退行性疾病（如视网膜色素变性、年龄相关性黄斑变性）导致的光感受器细胞损伤患者。以下是其核心要点：\n",
      "\n",
      "---\n",
      "\n",
      "### **1. 工作原理**\n",
      "- **替代光感受器功能**：通过植入微电极阵列（如硅芯片或柔性电极），将外部视觉信息转化为电信号，直接刺激视网膜残留的神经节细胞或双极细胞，绕过受损的光感受器层。\n",
      "- **信号传递路径**：电刺激信号经视神经传递至视觉皮层，形成光幻视（phosphene），患者可感知为点状或图案化视觉。\n",
      "\n",
      "---\n",
      "\n",
      "### **2. 技术类型**\n",
      "- **视网膜下植入**（如Alpha-IMS芯片）：置于色素上皮层与双极细胞之间，直接刺激内层视网膜神经元。\n",
      "- **视网膜上植入**（如Argus II系统）：位于神经节细胞层附近，需外部摄像头捕捉图像并无线传输至植入电极。\n",
      "- **皮质视觉假体**：绕过视网膜和视神经，直接刺激视觉皮层（适用于视神经损伤患者）。\n",
      "\n",
      "---\n",
      "\n",
      "### **3. 关键挑战**\n",
      "- **分辨率限制**：当前电极数量有限（如Argus II仅60电极），远低于人眼百万级光感受器，仅能提供低分辨率轮廓视觉。\n",
      "- **生物相容性**：长期植入可能引发炎症或电极降解。\n",
      "- **信号编码复杂性**：需匹配视网膜的自然编码方式（如时空动态编码），避免过度刺激导致失真。\n",
      "\n",
      "---\n",
      "\n",
      "### **4. 临床进展**\n",
      "- **现有产品**：Argus II（2011年FDA批准）可帮助患者识别物体轮廓和运动，但无法恢复精细视觉。\n",
      "- **研究方向**：柔性电极、光敏材料（如纳米线阵列）、基因治疗结合光遗传学（改造神经元使其对光敏感）。\n",
      "\n",
      "---\n",
      "\n",
      "### **5. 未来方向**\n",
      "- **高密度电极**：开发千级以上微型电极阵列，提升分辨率。\n",
      "- **闭环系统**：整合AI实时优化刺激参数，适应个体神经响应。\n",
      "- **跨学科融合**：结合光遗传学、干细胞技术修复视网膜神经网络。\n",
      "\n",
      "---\n",
      "\n",
      "如需更深入探讨某一方面（如具体技术对比或临床案例），可进一步补充说明。\n",
      "根据上下文中的代码片段，我可以提供以下具体的代码示例：\n",
      "\n",
      "1. 从神经网络层提取偏置参数的代码（来自第202页内容）：\n",
      "```python\n",
      "print(type(net[2].bias))\n",
      "print(net[2].bias)\n",
      "print(net[2].bias.data)\n",
      "```\n",
      "\n",
      "2. 优化算法中的状态变量初始化代码（来自第458页内容）：\n",
      "```python\n",
      "# s1和s2是稍后将使用的内部状态变量\n",
      "x1, x2, s1, s2 = -5, -2, 0, 0\n",
      "results = [(x1, x2)]\n",
      "for i in range(steps):\n",
      "    if f_grad:\n",
      "        # 这里应该有梯度计算的代码\n",
      "        pass\n",
      "```\n",
      "\n",
      "注意：第二个代码片段是不完整的，因为文档中显示\"(continues on next page)\"表示代码在下一页继续。如果您需要完整的优化算法实现，可能需要查看后续页面的内容。\n",
      "\n",
      "这些代码示例来自《动手学深度学习》一书的不同章节，分别展示了神经网络参数访问和优化算法实现的片段。\n",
      "根据提供的上下文信息，结合外科临床实践，我为您整理以下临床方案框架，重点涵盖急腹症处理、术后镇痛及ICU管理三个核心领域：\n",
      "\n",
      "---\n",
      "\n",
      "### **一、急腹症分层治疗方案**\n",
      "1. **非手术疗法适应证**  \n",
      "   - 病理损害轻、炎症局限（如：单纯性阑尾炎、水肿性胰腺炎）  \n",
      "   - **措施**：  \n",
      "     - 半卧位减少毒素吸收  \n",
      "     - 胃肠减压+禁食（梗阻/穿孔病例）  \n",
      "     - 广谱抗生素（如头孢三代+甲硝唑联合）  \n",
      "     - 静脉补液纠正水电解质失衡  \n",
      "\n",
      "2. **限期手术评估适应证**  \n",
      "   - 病情复杂但全身状态尚可（如：化脓性胆囊炎、阑尾周围脓肿）  \n",
      "   - **流程**：  \n",
      "     - 48小时内强化抗感染治疗（哌拉西林他唑巴坦等）  \n",
      "     - 每4小时评估腹痛/体温/WBC变化  \n",
      "     - 若24小时无改善→急诊手术  \n",
      "\n",
      "3. **急诊手术绝对适应证**  \n",
      "   - 缺血/坏死性疾病（如：绞窄性肠梗阻、坏疽性胆囊炎）  \n",
      "   - **术式选择**：  \n",
      "     - 腹腔镜探查优先（血流稳定者）  \n",
      "     - 开放手术（休克/肠坏死广泛者）  \n",
      "\n",
      "---\n",
      "\n",
      "### **二、术后多模式镇痛方案**\n",
      "1. **PCA技术选择**（根据手术创伤程度）  \n",
      "   | 类型       | 适用场景          | 药物配方示例                | 锁定时间 |\n",
      "   |------------|-------------------|-----------------------------|----------|\n",
      "   | PCIA       | 腹部中等手术      | 舒芬太尼1μg/mL+氟比洛芬酯  | 8分钟    |\n",
      "   | PCEA       | 开腹大手术        | 0.1%罗哌卡因+芬太尼2μg/mL  | 15分钟   |\n",
      "\n",
      "2. **辅助措施**  \n",
      "   - 术前宣教PCA使用方法  \n",
      "   - 每日2次疼痛评分（VAS/NRS量表）  \n",
      "   - 联合非甾体药物（帕瑞昔布静脉注射）  \n",
      "\n",
      "---\n",
      "\n",
      "### **三、ICU人文医疗实施方案**\n",
      "1. **隐私保护**  \n",
      "   - 操作时使用隔帘/屏风  \n",
      "   - 电子病历严格分级授权  \n",
      "\n",
      "2. **应激控制**  \n",
      "   - 每日家属沟通会（15:00-16:00）  \n",
      "   - 使用镇静量表（RASS）调控镇静深度  \n",
      "\n",
      "3. **早期康复**  \n",
      "   - 每日2次床上脚踏车训练（血流稳定后）  \n",
      "   - 音乐疗法（个性化播放列表）  \n",
      "\n",
      "---\n",
      "\n",
      "### **中西医结合要点**\n",
      "- 急腹症非手术期：大黄灌肠促进肠蠕动  \n",
      "- 术后康复期：针灸足三里促进胃肠功能恢复  \n",
      "\n",
      "需要针对具体病例进一步细化用药剂量和监测参数。\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory1 = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "memory2 = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "memory3 = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "chain1 = build_nr_chain(\"neuroscience_vector\", memory1)\n",
    "chain2 = build_dl_chain(\"deeplearning_vector\", memory2)\n",
    "chain3 = build_su_chain(\"surgery_vector\", memory3)\n",
    "\n",
    "# 交互界面\n",
    "print(\"系统就绪，输入问题开始对话（输入 'exit' 退出）\")\n",
    "print(f\"\\n{' 第1轮对话 ':=^50}\")\n",
    "response1 = \"\"\n",
    "response2 = \"\"\n",
    "response3 = \"\"\n",
    "query = input(\"\\n初始问题：\").strip()\n",
    "query1 = query\n",
    "query2 = query\n",
    "query3 = query\n",
    "# 回答采用流式输出，invoke 将问题传入到 Runnables 管道中\n",
    "for chunk in chain1.invoke(query1):\n",
    "    response1 += chunk\n",
    "print(\"=\" * 100)\n",
    "print(\"\\n神经科学专家的回答是：\")\n",
    "print(\"=\" * 100)\n",
    "print(response1)\n",
    "\n",
    "for chunk in chain2.invoke(query2):\n",
    "    response2 += chunk\n",
    "print(\"=\" * 100)\n",
    "print(\"\\n深度学习专家的回答是：\")\n",
    "print(\"=\" * 100)\n",
    "print(response2)\n",
    "\n",
    "for chunk in chain3.invoke(query3):\n",
    "    response3 += chunk\n",
    "print(\"=\" * 100)\n",
    "print(\"\\n外科专家的回答是：\")\n",
    "print(\"=\" * 100)\n",
    "print(response3)\n",
    "\n",
    "for i in range(2):\n",
    "    split_string = lambda str: (\n",
    "        str.split(\"</think>\", 1)[1] if \"</think>\" in str else str\n",
    "    )\n",
    "    # 将当前对话的问题和回答，保存到记忆缓冲区中\n",
    "    memory1.save_context({\"inputs\": query1}, {\"outputs\": split_string(response1)})\n",
    "    memory2.save_context({\"inputs\": query2}, {\"outputs\": split_string(response2)})\n",
    "    memory3.save_context({\"inputs\": query3}, {\"outputs\": split_string(response3)})\n",
    "    print(\"\\n\\n\")\n",
    "    query1 = input(\"请输入对于神经科学专家的评价，输入exit退出\")\n",
    "    query2 = input(\"请输入对于深度学习专家的评价，输入exit退出\")\n",
    "    query3 = input(\"请输入对于外科专家的评价，输入exit退出\")\n",
    "    if query1 == \"exit\" or query2 == \"exit\" or query3 == \"exit\":\n",
    "        break\n",
    "    print(f\"\\n{' 第' + str(i+2) + '轮对话 ':=^50}\")\n",
    "    response1 = \"\"\n",
    "    response2 = \"\"\n",
    "    response3 = \"\"\n",
    "    for chunk in chain1.invoke(query1):\n",
    "        response1 += chunk\n",
    "    print(\"=\" * 100)\n",
    "    print(\"\\n神经科学专家的回答是：\")\n",
    "    print(\"=\" * 100)\n",
    "    print(response1)\n",
    "\n",
    "    for chunk in chain2.invoke(query2):\n",
    "        response2 += chunk\n",
    "    print(\"=\" * 100)\n",
    "    print(\"\\n深度学习专家的回答是：\")\n",
    "    print(\"=\" * 100)\n",
    "    print(response2)\n",
    "\n",
    "    for chunk in chain3.invoke(query3):\n",
    "        response3 += chunk\n",
    "    print(\"=\" * 100)\n",
    "    print(\"\\n外科专家的回答是：\")\n",
    "    print(\"=\" * 100)\n",
    "    print(response3)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baae48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化知识库系统...\n",
      "系统就绪，输入问题开始对话（输入 'exit' 退出）\n",
      "回答：根据文档内容，深度学习是通过学习多层次的转换来进行多层次的表示学习的一类机器学习方法。它不仅取代了传统机器学习的浅层模型，还取代了劳动密集型的特征工程。深度学习已经彻底改变了模式识别，引入了一系列技术，包括计算机视觉、自然语言处理、自动语音识别等。\n",
      "\n",
      "\n",
      "\n",
      "==== 请继续对话（输入 'exit' 退出）====\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8f69d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化知识库系统...\n",
      "系统就绪，输入问题开始对话（输入 'exit' 退出）\n",
      "回答：根据文档内容，深度学习是机器学习的一个分支，它通过以下特点进行定义：\n",
      "\n",
      "1. **多层次表示学习**：深度学习通过学习多层次的转换（神经网络层）来自动提取数据的多层次抽象表示，属于表示学习的一种。\n",
      "\n",
      "2. **取代传统方法**：它不仅替代了传统机器学习的浅层模型（如线性回归、SVM等），还消除了人工设计特征的繁琐过程（特征工程），实现了端到端的学习。\n",
      "\n",
      "3. **驱动因素**：近年来的突破主要得益于：\n",
      "   - 大规模数据（来自廉价传感器和互联网应用）\n",
      "   - 算力提升（如GPU的广泛应用）\n",
      "\n",
      "4. **应用领域**：深度学习彻底改变了计算机视觉、自然语言处理、语音识别等模式识别任务，并成为许多先进应用（如医疗诊断、自动驾驶）的核心技术。\n",
      "\n",
      "简单来说，深度学习是通过多层神经网络自动学习数据复杂表示的机器学习方法，能够直接从原始数据中提取高级特征并优化整体系统性能。\n",
      "\n",
      "\n",
      "\n",
      "==== 请继续对话（输入 'exit' 退出）====\n",
      "回答：以下是基于PyTorch实现Transformer核心模块的Python代码示例（参考《动手学深度学习》内容）：\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import math\n",
      "\n",
      "class MultiHeadAttention(nn.Module):\n",
      "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
      "        super().__init__()\n",
      "        self.d_model = d_model\n",
      "        self.num_heads = num_heads\n",
      "        self.head_dim = d_model // num_heads\n",
      "        \n",
      "        self.wq = nn.Linear(d_model, d_model)\n",
      "        self.wk = nn.Linear(d_model, d_model)\n",
      "        self.wv = nn.Linear(d_model, d_model)\n",
      "        self.dropout = nn.Dropout(dropout)\n",
      "        self.out = nn.Linear(d_model, d_model)\n",
      "        \n",
      "    def forward(self, query, key, value, mask=None):\n",
      "        batch_size = query.size(0)\n",
      "        \n",
      "        # 线性投影 + 分头\n",
      "        Q = self.wq(query).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1,2)\n",
      "        K = self.wk(key).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1,2)\n",
      "        V = self.wv(value).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1,2)\n",
      "        \n",
      "        # 缩放点积注意力\n",
      "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
      "        if mask is not None:\n",
      "            scores = scores.masked_fill(mask == 0, -1e9)\n",
      "        attn = torch.softmax(scores, dim=-1)\n",
      "        attn = self.dropout(attn)\n",
      "        \n",
      "        # 合并多头\n",
      "        output = torch.matmul(attn, V).transpose(1,2).contiguous()\n",
      "        output = output.view(batch_size, -1, self.d_model)\n",
      "        return self.out(output)\n",
      "\n",
      "class PositionWiseFFN(nn.Module):\n",
      "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
      "        super().__init__()\n",
      "        self.linear1 = nn.Linear(d_model, d_ff)\n",
      "        self.linear2 = nn.Linear(d_ff, d_model)\n",
      "        self.dropout = nn.Dropout(dropout)\n",
      "        self.relu = nn.ReLU()\n",
      "        \n",
      "    def forward(self, x):\n",
      "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
      "\n",
      "class EncoderBlock(nn.Module):\n",
      "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
      "        super().__init__()\n",
      "        self.attention = MultiHeadAttention(d_model, num_heads, dropout)\n",
      "        self.norm1 = nn.LayerNorm(d_model)\n",
      "        self.ffn = PositionWiseFFN(d_model, d_ff, dropout)\n",
      "        self.norm2 = nn.LayerNorm(d_model)\n",
      "        self.dropout = nn.Dropout(dropout)\n",
      "        \n",
      "    def forward(self, x, mask=None):\n",
      "        # 残差连接 + 层归一化\n",
      "        attn_output = self.attention(x, x, x, mask)\n",
      "        x = self.norm1(x + self.dropout(attn_output))\n",
      "        ffn_output = self.ffn(x)\n",
      "        return self.norm2(x + self.dropout(ffn_output))\n",
      "\n",
      "# 简单测试\n",
      "d_model = 512\n",
      "num_heads = 8\n",
      "d_ff = 2048\n",
      "batch_size = 32\n",
      "seq_len = 100\n",
      "\n",
      "encoder = EncoderBlock(d_model, num_heads, d_ff)\n",
      "x = torch.randn(batch_size, seq_len, d_model)\n",
      "output = encoder(x)\n",
      "print(output.shape)  # 应保持输入形状: torch.Size([32, 100, 512])\n",
      "```\n",
      "\n",
      "关键点说明：\n",
      "1. **多头注意力**：通过并行多个注意力头捕捉不同子空间的依赖关系\n",
      "2. **位置前馈网络**：提供非线性变换能力\n",
      "3. **残差连接+层归一化**：缓解梯度消失问题（文档428页提到编码器不改变输入形状）\n",
      "4. **实际使用时**还需添加：\n",
      "   - 位置编码（Positional Encoding）\n",
      "   - 完整的Encoder/Decoder堆叠\n",
      "   - 任务特定输出层\n",
      "\n",
      "完整实现可参考文档437页提到的Vision Transformer论文(Dosovitskiy et al., 2021)。\n",
      "\n",
      "\n",
      "\n",
      "==== 请继续对话（输入 'exit' 退出）====\n",
      "对话结束\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import readline\n",
    "\n",
    "VECTOR_DIR = \"myvector\"\n",
    "MODEL_NAME = \"deepseek-r1:7b\"\n",
    "\n",
    "# 初始化会话记忆缓冲区，用于存储对话历史，保存在内存中\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "\n",
    "def build_qa_chain():\n",
    "\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=VECTOR_DIR,\n",
    "        embedding_function=DashScopeEmbeddings(model=\"text-embedding-v1\", dashscope_api_key=\"sk-b90be4e81ec04f1bada3c70f4368bebb\"),\n",
    "    )\n",
    "\n",
    "    openai_api_key = \"sk-7e37bea1ecc249968d28f386eb60b09e\"  #deepseek key\n",
    "    openai_api_base = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=openai_api_key,\n",
    "        openai_api_base=openai_api_base,\n",
    "        model = \"deepseek-chat\",\n",
    "        # model = \"qvq-max\",\n",
    "        # model = \"qwq-32b\",\n",
    "        temperature=0.7,\n",
    "        stop=['Observation:', 'Observation:\\n']\n",
    "    )\n",
    "\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,\n",
    "            \"fetch_k\": 20,\n",
    "            \"lambda_mult\": 0.5,\n",
    "            \"score_threshold\": 0.4,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    system_template = \"\"\"\n",
    "        您是一名一个设计用于査询文档来回答问题的代理。\n",
    "        您可以使用文档检索工具，并基于检索内容来回答问题。\n",
    "        您可能不查询文档就知道答案，但是您仍然应该查询文档来获得答案。\n",
    "        如果您从文档中找不到任何信息用于回答问题，则只需返回“抱歉，这个问题我还不知道。”作为答案。\n",
    "        如果有人提问等关于您的名字的问题，您就回答：“我是小天才助手”作为答案。\n",
    "        上下文：{context}\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate(\n",
    "        [\n",
    "            (\"system\", system_template),\n",
    "            MessagesPlaceholder(\"chat_history\"),  # 将历史对话插入到模板中\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"context\": retriever,\n",
    "            \"chat_history\": lambda x: memory.load_memory_variables({})[\"chat_history\"],\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "def console_qa():\n",
    "    print(\"初始化知识库系统...\")\n",
    "    chain = build_qa_chain()\n",
    "    print(\"系统就绪，输入问题开始对话（输入 'exit' 退出）\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\n问题：\").strip()\n",
    "            if not query or query.lower() in (\"exit\", \"quit\"):\n",
    "                break\n",
    "\n",
    "            print(\"回答：\", end=\"\", flush=True)\n",
    "            response = \"\"\n",
    "            \n",
    "            for chunk in chain.invoke(query):\n",
    "                response += chunk\n",
    "            print(response)\n",
    "            # 截取 </think> 后面的字符串\n",
    "            split_string = lambda str: (\n",
    "                str.split(\"</think>\", 1)[1] if \"</think>\" in str else str\n",
    "            )\n",
    "            # 将当前对话的问题和回答，保存到记忆缓冲区中\n",
    "            memory.save_context({\"inputs\": query}, {\"outputs\": split_string(response)})\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "            print(\"==== 请继续对话（输入 'exit' 退出）====\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    console_qa()\n",
    "    print(\"对话结束\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
